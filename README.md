# SogangML
이종욱 20151162

ex1 notebook installation

ex2 ls1

Overcome Overfitting Problem(using validation set) https://nittaku.tistory.com/289, https://medium.com/machine-learning-intuition/overfitting-what-they-are-regularization-e950c2d66d50


#1. validation set을 train set과 k-fold cross validation을 이용하여 비교한다.(train set 보다 낮으면 오버피팅) https://nonmeyet.tistory.com/entry/KFold-Cross-Validation%EA%B5%90%EC%B0%A8%EA%B2%80%EC%A6%9D-%EC%A0%95%EC%9D%98-%EB%B0%8F-%EC%84%A4%EB%AA%85

#2. Regularization(smooth해질때까지)을 반복 (=variance를 낮춤)

#3. 조기종료(early stopping) : stop(repetititon of epohces)  just before validation's accuracy get worse than the train's.

ex3 ls2 uploaded

ex4 ls3
